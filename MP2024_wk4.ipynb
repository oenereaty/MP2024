{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 이전까지 배웠던 것들",
   "id": "6a01821ec3d923c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:46:38.663514Z",
     "start_time": "2024-10-06T14:46:18.334824Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "import datasets\n",
    "import transformers\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch # 파이토치"
   ],
   "id": "f5f7b15716641264"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:50:23.720006Z",
     "start_time": "2024-10-06T14:50:23.712573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dict = {\n",
    "    'text': [\n",
    "        \"I prefer making decisions based on logic and objective facts.\",\n",
    "        \"I always consider how others might feel when making a decision.\",\n",
    "        \"Data and analysis drive most of my decisions.\",\n",
    "        \"I rely on my empathy and personal values to guide my choices.\"\n",
    "    ],\n",
    "    'label': [0, 1, 0, 1]  # 0은 T(사고형), 1은 F(감정형)\n",
    "}\n",
    "\n",
    "test_dict = {\n",
    "    'text': [\n",
    "        \"I find it important to weigh all the pros and cons logically.\",\n",
    "        \"When making decisions, I prioritize harmony and people's emotions.\"\n",
    "    ],\n",
    "    'label': [0, 1]  # 0은 T(사고형), 1은 F(감정형)\n",
    "}"
   ],
   "id": "6b1b2d2725f2ec71",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:51:30.260585Z",
     "start_time": "2024-10-06T14:51:30.242643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = datasets.Dataset.from_dict(train_dict)\n",
    "test_data = datasets.Dataset.from_dict(test_dict)\n",
    "나의데이터 = datasets.dataset_dict.DatasetDict({'train':train_data, 'test':test_data})"
   ],
   "id": "673a619a99788db3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:51:34.117817Z",
     "start_time": "2024-10-06T14:51:34.110328Z"
    }
   },
   "cell_type": "code",
   "source": "나의데이터",
   "id": "978b7dc6efa301b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:53:05.908847Z",
     "start_time": "2024-10-06T14:53:02.781358Z"
    }
   },
   "cell_type": "code",
   "source": "데이터전처리하기1 = 토크나이저 = transformers.AutoTokenizer.from_pretrained('distilbert-base-uncased')",
   "id": "e3699263a5892aec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7258ff7d83824fb6b658c5dd56d72c2d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qnsgh\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\qnsgh\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ccfc6b3a060142e689219a58600ccded"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae0186c5096640489dc1e112485b44f2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0285310b6d9348ee82bb17e641ed4a7e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qnsgh\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:37:51.128917Z",
     "start_time": "2024-10-07T15:37:50.840415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "인공지능 = model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\",\n",
    "    num_labels=2 )\n",
    "# ^^^ 인공지능 생성기\n",
    "\n",
    "\n",
    "인공지능.classifier.weight\n",
    "# ^^^ 인공지능의 대량의 숫자들(tensor)"
   ],
   "id": "ba47405c0afcfbb5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0032, -0.0022, -0.0045,  ...,  0.0322,  0.0115, -0.0124],\n",
       "        [ 0.0261,  0.0465,  0.0261,  ...,  0.0176,  0.0243, -0.0202]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`-` 인공지능: 인공지능의 파라메터는 변화할 수 있으며, loss가 더 작은쪽으로 파라메터를 변화시키는 과정을 “학습”이라고 부른다.\n",
    "\n",
    "`-` 인공지능: 인공지능은 “`**Dict \n",
    " transformers.modeling_outputs.SequenceClassifierOutput”`인 함수이다. 그런데 쓰기 까다롭다.\n",
    "\n",
    "- `1.` `Dict`에는 특정한 key를 포함하고 있어야한다. (input_ids, attention_mask)\n",
    "- `2.` `key`에 대응하는 숫자는 !파이토치 텐서!형태이어야 한다.\n",
    "\n",
    "```Python\n",
    "    np.array([1,2,3]) VS. torch.tensor([1,2,3])\n",
    "   ```\n",
    "^^^ 인공지능을 학습시키기 위해 GPU가 필수인데, 후자의 경우가 GPU에 특화된 입력 형태 $\\to$ (`3.` 따라서 (m,n)꼴의 차원을 반드시 가져야 한다. 값이 존재하지 않으면 0으로 메꾸는 형태...Truncation, Padding etc)\n",
    "- `4.` `Dict`에 `labels`이 (텐서형으로) 포함된 경우 loss가 계산된다. (그리고 이걸 계산해야지 학습을 할 수 있음)"
   ],
   "id": "8139940821913bd8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:37:24.207563Z",
     "start_time": "2024-10-07T15:37:24.136740Z"
    }
   },
   "cell_type": "code",
   "source": "토크나이저(나의데이터['train']['text'][0])",
   "id": "d89a7493055320f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 9544, 2437, 6567, 2241, 2006, 7961, 1998, 7863, 8866, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:37:24.816018Z",
     "start_time": "2024-10-07T15:37:24.807725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "인공지능입력1 = {\n",
    "        'input_ids': torch.tensor([[ 101, 1045, 102],[101, 9544, 102]]), \n",
    "        'attention_mask': torch.tensor([[1, 1, 1],[1, 1, 1]]) # 생략가능\n",
    "}\n",
    "\n",
    "# ^^^ 2번 설명 자료"
   ],
   "id": "496ba9fa237e13e4",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:37:25.756271Z",
     "start_time": "2024-10-07T15:37:25.744711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "궁금 = 토크나이저(나의데이터['train']['text'][0])\n",
    "type(궁금['input_ids'])"
   ],
   "id": "ba0ae8e9f07c67b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:43:57.528373Z",
     "start_time": "2024-10-07T15:43:57.464048Z"
    }
   },
   "cell_type": "code",
   "source": "인공지능(**인공지능입력1)",
   "id": "67a55008f47bf487",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[0.0399, 0.0468],\n",
       "        [0.0289, 0.0282]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "여기서 `인공지능입력1`이란 단순히 `torch.tensor(input_ids)` 의 값을 의미하며(<1>`input_ids` 말고 `attention_mask`도 올 수 있음. 후자의 경우는 선택임. \n",
    "\n",
    "<2> `torch.tensor(input_ids)`는 인공지능의 확신 정도(?)를 의미함.), 함수 `인공지능(**인공지능입력1)` 은 인공지능 model의 logits 값을 출력함.\n",
    "\n",
    "여기서는 `labels` 가 없기 때문에 이 인공지능이 정상적으로 수행하는지 검토하는 사용으로 활용됨. (=학습 목적이 아님.)\n"
   ],
   "id": "fff916b4b5f393c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:50:39.730491Z",
     "start_time": "2024-10-07T15:50:39.722660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "인공지능입력2 = {\n",
    "        'input_ids': torch.tensor([[ 101, 1045, 102],[101, 9544, 102]]), \n",
    "        'attention_mask': torch.tensor([[1, 1, 1],[1, 1, 1]]), # 생략가능\n",
    "        'labels': torch.tensor([1, 0]) # 생략가능\n",
    "}"
   ],
   "id": "7a3f193a160b8e77",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:50:41.160435Z",
     "start_time": "2024-10-07T15:50:41.097550Z"
    }
   },
   "cell_type": "code",
   "source": "인공지능(**인공지능입력2)",
   "id": "301d3758a9956ebe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.6913, grad_fn=<NllLossBackward0>), logits=tensor([[0.0399, 0.0468],\n",
       "        [0.0289, 0.0282]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**인공지능입력1과 달라진 것들** :\n",
    "\n",
    "1. 입력값에 `labels`가 추가됨: 음... `labels`는 마치 수학 문제집의 정답지 역할을 함. 인공지능입력1이 그저 문풀만 했다면(∵ `labels`가 없어서), 인공지능입력2는 `labels`가 추가됨에 따라 인공지능이 스스로 학습할 수 있음.\n",
    "\n",
    "2. loss의 값이 등장함: `labels`가 새롭게 추가 되었기 때문.(정답지를 보고 자신의 점수(=`loss`)를 확인할 수 있음."
   ],
   "id": "b4f9f7b477455cf8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T09:07:03.773984Z",
     "start_time": "2024-10-08T09:07:03.657965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "인공지능출력 = 인공지능(**인공지능입력2)\n",
    "로짓 = 인공지능출력.logits\n",
    "로짓"
   ],
   "id": "8f811ace85cfa633",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0399, 0.0468],\n",
       "        [0.0289, 0.0282]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T09:07:04.814853Z",
     "start_time": "2024-10-08T09:07:04.796979Z"
    }
   },
   "cell_type": "code",
   "source": "torch.exp(로짓) / torch.exp(로짓).sum(axis=1)",
   "id": "6b1606f98499fcdc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4983, 0.5092],\n",
       "        [0.4928, 0.4998]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "sum(axis=1)이란 한 행을 모두 더하라는 걸로 알고 있음. (추후 최규빈 교수님의 파이썬 프로그래밍 강좌를 다시 보자.)\n",
    "\n",
    "그래서, \n",
    "\n",
    "```Python\n",
    "torch.exp(로짓) / torch.exp(로짓).sum(axis=1)\n",
    "```\n",
    "로짓 = [0.0399,0.0468] 일 때, 그에 대한 exp 값은\n",
    "\n",
    "[exp(0.0399)/{exp(0.0399) + exp(0.0468)} , exp(0.0468)/{exp(0.0399) + exp(0.0468)} ] 이 됨."
   ],
   "id": "7144b3edbb1a1035"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T09:07:05.233604Z",
     "start_time": "2024-10-08T09:07:05.225976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def 확률계산하기(인공지능출력):\n",
    "    로짓 = 인공지능출력.logits\n",
    "    return torch.exp(로짓) / torch.exp(로짓).sum(axis=1)"
   ],
   "id": "e3e3be47c66716f",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T09:07:05.609550Z",
     "start_time": "2024-10-08T09:07:05.558665Z"
    }
   },
   "cell_type": "code",
   "source": "확률계산하기(인공지능(**인공지능입력2))",
   "id": "dc346681706857e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4983, 0.5092],\n",
       "        [0.4928, 0.4998]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "당연히 확률이므로, 합하면 1이 됨. 이 프로그램은 T/F를 찾는 인공지능을 만들고 있으며 각각 0, 1에 대응함.\n",
    "\n",
    "확률을 보면 거의 반반이라는 것을 알 수 있는데, 이는 인공지능이 아주 아주 멍청한 상태(∵ 학습을 하지 않았기 때문.)라는 것을 알 수 있음.\n",
    "\n",
    "\"그냥 아무거나 찔러본다\" 라고 생각하자."
   ],
   "id": "77a53c83f99f24e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:58:43.227563Z",
     "start_time": "2024-10-07T15:58:43.107944Z"
    }
   },
   "cell_type": "code",
   "source": "전처리된나의데이터 = 나의데이터.map(lambda dct: 토크나이저(dct[\"text\"], truncation=True))",
   "id": "30e733cfad2ad8c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9982913c0fc4346964126f663562951"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a76e29c4d0d1452ca19add30213fa207"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`map()`함수는 <1> function을 입력값으로 받음.\n",
    "```Python\n",
    "나의데이터.map(lambda dct: 토크나이저(dct[\"text\"], truncation=True))\n",
    "```\n",
    "가 가능한 이유.\n",
    "\n",
    "<2> function 중에서도 `dict`를 받음. dict라고 한다면 `DatasetDict`가 생각나야 할 것이다!\n",
    " "
   ],
   "id": "918a88c2680f7b76"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 데이터콜렉터 (더 전처리 된 데이터)",
   "id": "e7df1f7d6209b140"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "목적: 인공지능이 학습하기 쉽게 행렬의 형태로 만들기. tokenizer의 전처리 이후 실행하므로 숫자화(O), datacollator로 인해 행렬화한다.ㅡ\n",
    "\n",
    "`torch.tensor`, `미니배치`, `패딩/동적패딩` 모두 O.  (당연함. 인공지능의 학습을 위해 구조를 떠먹어줘야 하기 때문.)\n",
    "\n",
    "datacollator를 위해 `dictionary`의 형태로 바꿔줘야 함.(`label`, `text`, `input_ids`, `attention_mask`)\n"
   ],
   "id": "8dac960feefd9692"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 평가하기 (accuracy)",
   "id": "4e3a560c66c44e09"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T09:13:00.793365Z",
     "start_time": "2024-10-08T09:12:59.194071Z"
    }
   },
   "cell_type": "code",
   "source": "accuracy = evaluate.load(\"accuracy\")",
   "id": "165294841a19b723",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T09:13:06.311567Z",
     "start_time": "2024-10-08T09:13:06.234388Z"
    }
   },
   "cell_type": "code",
   "source": "accuracy.compute(predictions=[0,0,0], references=[0,0,0])",
   "id": "772c54e51f473a21",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T09:13:13.163645Z",
     "start_time": "2024-10-08T09:13:13.129979Z"
    }
   },
   "cell_type": "code",
   "source": "accuracy.compute(predictions=[1,0,0], references=[0,0,0])",
   "id": "b5f92f838ce0ed67",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6666666666666666}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# to(\"cuda:0\")",
   "id": "218af2edcb7b8eea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```Python\n",
    "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This was a masterpiece.\")]).to(\"cuda:0\")))\n",
    "```\n",
    "\n",
    "`.to(\"cuda:0\")` 는 해당 데이터를 GPU 상에 두었다는 것을 의미함.\n",
    "\n",
    "만약 데이터 간 위치(GPU vs. CPU) 가 다르다면 코드가 돌아가지 않음. 하나로 통일해줘야 함.\n"
   ],
   "id": "38100321093cde0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "44a29af4f98712de"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
